---
#bibliography: bib/references_conclusion.json
---
# Conclusion {-}

I began my graduate research program with the intention to study how a cognitive system evolves such that it is capable of understanding complex societies and building sophisticated technologies, as seen in human behavior. My foundational hypothesis was that the foraging behavior of primates and other species that share their ecology would reveal the basic features of such cognitive systems. The most useful idea I found in the pursuit of this goal is that of the cognitive map. In this conclusion, I will outline the contours of how I understand cognitive maps now, which differs considerably from how I understood cognitive maps when I designed each of my chapters, and which itself differs from how I understood cognitive maps as I wrote the chapters. Once my personal theory of cognitive maps is briefly laid out, I will highlight some of the ways my research helped my views to evolve and discuss some ways I believe that this theory could shape the future of ecological research. Finally, I will consider some of the emerging bridges between the research fields of artificial intelligence and animal cognition that I think have the most potential, especially those that might ead to mathematical models necessary for formally testing conceptual theories of cognitive maps.

## Building a Cognitive Map

The concept of the cognitive map is, at its core, an analogy. In the conclusion to *Purposive Behavior in Animals and Men", Tolman writes

>
>"All science necessarily presents, it seems to us, but a map and picture of reality. If I were to present reality in its whole concreteness, science would be not a map, but a complete replica of reality. And then it would lose its usefulness. For it would have to cover as many pages as does life itself; it would no longer serve as a brief and a handbook. One of the first requisites of a science is, in short, that it be a map, i.e. A short-hand for finding one’s way about from moment of reality to the next—that it be a symbolic compendium by means of which to predict and control.
Our account of the mind, we hold, is a map account."
>

The central question Tolman attempts to answer in his book is "how do animals make this map?" The framework he presents is rigorous and insightful, but also sprawling, complex, and somewhat archaic - no doubt a reason that its influence in psychology was slow to emerge and often misunderstood. Here, I draw on this framework, as well as more modern accountings and my own insights, to present a simpler outline of the cognitive map's primary mechanics (as I understand it).

The simplest definition of a cognitive map I can offer is "a hierarchical representation of the state of the world, built from memory by the combined processes of inference and reinforcement." At the lowest level, inference occurs when an animal determines that one perceptual scene is "like" another. It can then use the outcomes of its behavior in that previous scenario to guide its decisions in the current moment. If the outcomes of the two scenarios are congruous, the shared elements of the scenarios can be stored in a *scheme*. Schema reduce the information in a perceptual scene to a subset of important features, and they are the building blocks of a cognitive map. Learning occurs when an outcome causes the connections between the schema and motor pathways activated prior to that event to become reinforced. In this way, animals learn not only how to respond to specific perceptual cues, but also how to make inferences across increasingly disparate and diverse scenarios by attending to their most important features. The network of associations between schema that an animal builds over time - its semantic knowledge - allows the animal to translate a given perceptual scene into a representation of possible actions and their outcomes - a cognitive map.

My hope, in presenting this highly simplified explanation of a cognitive map, is to highlight how reinforcement and inference are highly integrated processes that build on each other to produce intelligent behavior. This view contrasts with the one I held entering this dissertation that reinforcement and inference form a dichotomy. On one side of such a dichotomy, reinforcement produces stable patterns of action that can only be changed by repeated, countervailing experience. On the other side, inference is a separate cognitive faculty that enables some animals to behave optimally without the need for reinforcement. The research I have presented offers several opportunities to consider why the idea of a cognitive map depicts nuance in the relationship between reinforcement and inference that is necessary for studying the behavior of intelligent animals in complex environments.

Take the differing responses of primates placed into small foraging arrays in Chapter 1, for example. The vervets and Japanese macaques needed no experience to adopt efficient movements between resource platforms. Despite the novelty of the platforms and their arrangement, these primates inferred an efficient way to acquire all of the food. The strepsirrhines did not. Instead, the strepsirrhines spent many of their initial trials exploring. Only with repeated exposure did strepsirrhines begin showing behaviors that indicated they had inferred, from previous trials, properties of they array: they focused more on the platforms, avoided returning to the same platforms, and in a few cases began to consistently follow efficient routes between all platforms. Because this project lacked an experimental component and there were confounding differences in the nature of the strepsirrhine environments and those with vervets and Japanese macaques, it is impossible to say what drives the observed differences. That the strepsirrhines evevntually prove themselves capable of navigating the arrays as efficiently as vervets and Japanese macaques, however, emphasizes the question of why they do not do it in the first place. Perhaps their different sensory organs perceive the scene differently and the food is less salient to them; perhaps they have less prior experience with arrays of depleting resources than the vervets and macaques. Or, perhaps the reinforcement of schema in their cognitive maps is more modular, and less likely to bridge between disparate contexts, even if they share some salient features. Future work could resolve these alternative hypothesis by sequentiall introducing individuals of each species to arrays of different scales (eg one-half or twice the sizes used in Chapter 1), and in different contexts (eg. light vs dark, different colored rooms). The differently sized arrays would enable measurement of how learning rates change with the scale of the array, which makes for more robust comparisons between species. Introducing the same individual to arrays in different contexts would allow some control over experience, allowing to measure how individuals generalize their experiences, instead of just guessing.

In Chapter 2, kinkajous face the opposite problem: a familiar environment where the resource array changes. In this case, kinkajous may still benefit from learning movement patterns through the tree crown that optimize foraging success on average (direct reinforcement of cues such as crown structure to motor action). In addition, kinkajous might hypothetically learn strategies that help them efficiently exploit the specific array of flowers on a given night (reinforcing the use of particular schema, e.g. the appearance of flowers on one branch that commonly blooms synchronously with a branch in another region). However, at the scale of our analysis we found neither patterns that could be exploited as such, nor much variation in flower distribution at all. Such absence was reflected in the apparent randomness of kinkajous' movements within the crown.

Analyzing the results of the first two chapters from the perspective of reinforcement and inference illustrates how animals, if they are to exploit the patterns of an ever-changing world, must move beyond simple stimulus-action reinforcement. They need to use schema to make inferences - learning occurs as they reinforce the use of schema that enable better inferences. This type of learning usefully describes the process of developing semantic knowledge from episodic memory. A sense of the cognitive map begins to emerge when considering how an animal combines its knowledge of multiple schema to conceptualize its current context and the actions that would be most useful. The nature and value of the cognitive map becomes clearer when considering it in an explicitly spatial context, as done in Chapters 3 and 4.

The results of Chapter 3 illustrate how kinkajous use both reinforcement and inference to behave efficiently and flexibly throughout space. In some places, the high resolution tracking of Tony Stark reveals incredibly consistent paths through the canopy, indicating the power of reinforcement to develop efficient behavior in a complex environment. Yet, these paths are used in two directions. This could not be achieved by simply reinforcing stimulus-action responses, as the stimuli moving the opposing directions are likely very different. Instead, an animal learning to use a route bi-directionally might reinforce schema along the route that includes schema of where the animal has been. A couple interesting factors become apparent here. First, the hierarchical nature of a cognitive map; while lower order schema might store the salient features of a simple concept, like a certain type of object, higher order schema organize lower order schema into increasingly complex concepts, such as a place. Second, the use of bi-directional routes demonstrates the role of cognitive maps in allowing an animal to represent the state of the world outside of its current perceptual context by building associations. As Tony Stark learns to use a route in one direction, if the schema he builds are associated with schema of where he has been, he will be better able to infer the utility of using the route in the other direction. 

This same idea applies to the intersections in a kinkajou's route network, but with added complexity. These points in space are not just used for two navigational goals, but three or more. In the food provisioning experiment with Molly, she rapidly integrated provisioning locations into her nightly movements and developed more direct routes between these locations. Though route intersections could emerge if different behaviors are reinforced according to different motivations (e.g. food vs. water), this is not sufficient to explain Molly's behavior. Instead, Molly's behavior suggests she has previously reinforced associations between movement decisions at important intersections and particular place schema. If her scheme for a place changes, say because she has recently found food there, it can influence her decision at an intersection previously associated with the place, but not the food. I have taken some liberty in describing the results of this chapter, as the limited data do not rule out many alternative hypotheses, but what I hope to have illustrated is that the flexible navigation of kinkajous can not be explained by magnitudes of reinforcement learning and/or inference alone; it requires a theory of how reinforcement and inference create a feedback loop that can build an increasingly complex system of knowledge like a cognitive map.

If the behavior of the kinkajous tracked in Chapter 3 point toward an integrated role of reinforcement and inference in the development of a cognitive map, Chapter 4 provides evidence of this process in action. The analysis takes the assumption that animals know of a relationship between two locations, but the connections may be indirect or through weakly reinforced schema. If a change occurs in the animal's cognitive map, e.g. the appearance of new food at one of these two locations, and that change motivates the need for a more direct route, the animal may follow the known connections, but use learned strategies for orientation to build more direct and reinforced schema along the way. Examples of this could include learning new landmarks on the physical path that aid in orientation, or cutting landmarks out of the route by finding a direct connections between the landmarks that come before and after. As an animal's route shifts through space, it will need to infer the utility of new places it visits, then reinforce those schema that are most useful. By measuring the rate at which animals build direct routes between locations separated by varying distances, we are able to assess how they balance reinforcement of paths that work with learned strategies for inferring new choices that may produce better results.

In summary, each chapter of this dissertation finds animals attempting to navigate ever-changing worlds, but the factors that change differ from chapter to chapter. In each case, the changing features render simple stimulus-action reinforcement ineffective for producing optimal behavior. Instead, optimal behaviors could be produced by reinforcing the use and associations of schema that mediate between perception and action, allowing for inference. In the first two chapters, these inferences involve strategies for serial decision-making in local, multi-destination arrays. In chapters 3 and 4, the problem expands to environments that are only partially observable, and thus call for a more complex cognitive map that, through hierarchical organization, can build concepts of places and their spatial properties. Across all chapters, the data reveal variance between individuals and species in how quickly they learn optimal behaviors, and the breadth of contexts between which they can make inferences.

One piece that is largely missing from these studies is the development of cognitive maps over an individual's lifetime, or across different experimental contexts. The methods of analysis developed in this work opens the door to rigorously conduct such research. These efforts would be greatly supplemented by the formalization of a cognitive map model, as is happening in the field of artificial intelligence, enabling the simulation of learning (and emergent behaviors) across parameter values that balance inference and reinforcement. Taken together, these efforts could integrate theories of learning with ecological theories such as optimal foraging and the ecological constraints model. In the following sections, I outline further details about the directions this research could take.

## Modelling a Cognitive Map

Inference is of primary interest to AI scientists, and is generally studied within the field under the moniker "first-trial learning". First-trial learning refers to the ability of an agent to behave more optimally upon its first exposure to a new environment if it has previously had experience in a different environment with some shared properties (relative to agents that have no previous experience). 

One of the algorithms most proficient in first-trial learning is called Projective Simulation (PS; @briegel2012), which draws explicitly on the ideas of episodic memory, schematization, and reinforcement outlined in the previous section. In the infinite color game, for example, a PS agent is presented with a simple perceptual scene (percept) that contains two elements, an arrow with one of a discrete set of $n$ directions and a random color drawn from the continuous color space. The actions the agent can take correspond to the directions of the arrows, and the goal is for agents to learn to chose the action that matches the arrow direction in a percept. The first step for the algorithm to achieve this is to create a network of encountered percepts (episodic memory), 'wildcard generalizations' (nodes in the graph that replace at least one element of percept vector with a '#' symbol, i.e. schema), and actions. Second, when an agent encounters a new percept (which occurs at every step because every color is unique), it creates edges between that percept's node in the memory network and any wildcard nodes to which it can be generalized. It then conducts a random walk through the network, starting at the current percept node and ending when it arrives at an action. Finally, when the agent successfully matches an action to the observed arrow direction, the weight of all the network edges it traversed prior to that decision are reinforced, increasing their likelihood of being followed again in the future [@melnikov2017]. Over time, the links between wildcard schema that contain only arrow direction information become strongly linked to the correct actions, and this architecture thus provides a computationally simple means for the agent to derive the relevant properties of a scene, even when no two scenes are ever the same.

Though it is unsurprising to see that principles of psychology, developed in large part through the study of animal behavior, have been influential in the field of Artificial Intelligence (AI), the insights of AI research have been slower to make their way back to behavioral ecology. The most obvious reason for this is that applying these insights to the behavior of real animals in complex environments is among the most difficult class of AI problems. @russell2020 identify seven binaries that categorize the difficulty of an environment in terms of its difficutly for AI to solve, noting that "the hardest case is *partially observable, multiagent, nondeterministic, sequential, dynamic, continuous, and unknown.* Without going into detail about each of these qualities, I will suffice it to say they clearly describe the conditions of Chapters 3 and 4 (and also the first two chapters, if one considers the role of the external environment in the animals' behavior - e.g. how changing abundance of other food sources affected the time kinkajous spent in the balsa tree studied in Chapter 2). The types of algorithms that can handle these types of environments are new, and require specialized study to implement (@russell2020's 1200 page volume is an *introductory* text to the study of these algorithms). The Projective Simulation algorithm in the infinite color game addresses only the 'continuous' problem of challenging environments. Nonetheless, emerging AI algorithms have enormous potential for informing the development of new models relating individual learning to the emergence of group- and population-level phenomena in behavioral ecology.

I believe that the cognitive map concept will be essential for filling this gap. Consider a hypothetical version of Projective Simulation that includes a 'working memory' element of each percept. This working memory might contain a vector for each possible action the agent can take (memory vector), with a magnitude equal to the number of times that action was taken since some event (e.g. a successful foraging action). Like the colors in the infinite color game, the possible vectors that could be held in this element are infinite, but need only be added to the memory network as they are experienced, with links to the wildcard nodes that generalize the vectors away. Such functionality would enable agents to learn about the 'distance' and 'direction' between experiences and schema, the key features of a cognitive map. If the structure of nodes representing memory vectors is further constrained such that the connection between a node in vector $x$ of magnitude $i$ and a node in vector $y$ of magnitude $j$ is equal to $r_{xy} \lvert i-j \rvert$, where the value of $r_{xy}$ that minimizes an agent's surprise can be learned, I believe agents in a spatial foraging task would begin to use novel shortcuts. The true power of such an approach, however, is that it need not be applied only to spatial domains; it would allows an agent to learn generally about how its actions change its environment and the relationships between different actions and their consequences.

## The role of Cognitive Map models in Optimal Foraging

The notion of an intelligent agent that can solve foraging tasks in the most challenging environmental cases begs the question of how such agents will behave relative to real animals. For example, the Marginal Value Theorem predicts that animals will stop foraging in a patch when the rate of return in that patch falls below the average rate of return in the environment, including the time costs of travel [@charnov1976]. This theorem assumes that an animal has perfect knowledge of the average return rate and distance of foraging patches in its environment, but no knowledge of the locations or values of specific patches. Perfect knowledge of the average environment seems unlikely for animals, and Chapter 4 adds to a large body of evidence that animals have some knowledge of future destinations. None-the-less, early research using relatively simple systems found that foraging behavior matched the predictions of the Marginal Value Theorem in species as diverse as black-capped chickadees [@krebs1974], great tits [@cowie1977], hummingbirds [@pyke1978a], chipmunks [@giraldeau1982], and bumblebees [@cibula1984; @pyke1978]. However, subsequent work found that animals generally overstay in patches [@nonacs2001], but sometimes leave energy rich patches too early [@alonso1995]. The ability of animals to match Marginal Value Theorem predictions can be explained by learning models that closely approximate the solution using limited memory [@belisle1997], while deviations from these predictions have been attributed to animals learning to leave a patch based on multi-scale foraging contexts (e.g. they leave a quality patch sooner if they know it to be in a high quality region) [@watanabe2014]. Deviations for optimal foraging may also result from animals learning to satisfice multiple competing demands, rather than maximize energy intake [@alonso1995]. A formal cognitive map model of learning could explain such higher order learning, and lead to the derivation of new marginal value predictions based on the multi-scale foraging challenges faced by most animals in real environments.

I will conclude by (1) re-iterating the distinction posed in my introduction between cognitive map models of *knowledge* often used in movement ecology and cognitive map models of *learning* used in psychology, (2) emphasizing the reasons my research motivates a need to integrate cognitive map models of learning into ecological research, and (3) briefly speculating on the power of cognitive map models of learning to extend beyond foraging behavior and into higher level processes like social learning and theory of mind. 

(1) In ecological research, cognitive models generally have a spatially explicit structure; they are useful for assessing how animals make decisions under the assumption they already know relevant features of the environment are location. In psychology, cognitive map models the the way a network of ideas is constructed to hold information about the distance and direction seperating these ideas. These models are useful for understanding how an animal can develop spatially explicit knowledge in the first place, and have the added benefit of being useful for explaining learning in non-spatial domains. 

(2) In my dissertation, I have illustrated how movement decisions and patterns of navigation differ in contexts with small and large spatial scales. Yet, I also observe there is a link between the ways animals learn the strategies effective for each context. Cognitive map models of learning can unify accounts of how animals learn heuristics for navigating arrays within local, perceptually available scenes, and how animals learn routes that traverse the continuous space between distant patches. They provide a means of explaining (and predicting) the inferences animals make (e.g. the relevant context of a novel scene, or a shortcut between patches) that are typically baked into cognitive map models of knowledge. 

(3) Finally, cognitive map models of learning should, in theory, allow for learning beyond spatial domains, such as social domains - so long as the agent or animal can perceive the other relevant actors and learn how sequences of its own actions intervene between one state of the world and the next. If true, these models could be integrated into our understanding of how animals respond to each other in their movements, offering insights into how animals achieve an ideal free distribution [@krivan2008] or modulate group size according to ecological constraints [@chapman1990].

To achieve these ends, behavioral ecologists and computer scientists will need to bring their domains of knowledge together. Many behavioral ecologists conducting research like my own are building substantial knowledge of what inferences animals make, and when. Computer scientists are increasingly able to explain how intelligent systems learn to make sophisticated inferences by integrating episodic memory and reinforcement learning into hierarchical networks of knowledge. These systems relate perceived world-states according distances and directions along an agent's action space, much like Tolman described cognitive maps. Somewhere between the leading edges of these two fields, there is a predictive model of animal foraging in stochastic, multi-scale environments that does not need to assume animals possess *a-priori* representations of topological space. The route through this space just needs to be mapped.