---
title: "Primate DET Report"
author: "Alexander Vining"
date: "8/10/2020"
output: html_document
---

The report details two analyses. The first is an attempt to reproduce the results of Ayers et al. 2018 simulations in NetLogo using my own simulation in R. The reason for this is that by creating my own code, I am able to produce outputs that are easier to use and more flexibly manipulate parameters that the NetLogo simulation was not designed for. My model can also serve as the basis for many additional models that may be outside the scope of NetLogo. However, I need to be sure mine works the same as Ayer's 2020 before I use it draw conclusions. I describe the simulations conducted below, but have not included the raw simulation code in this report, only the statistical analysis.

Second, I used the model I created and validated to explore how resource selection type affects DET at different levels of sight range when patches are arrayed in the "Double Trapezoid" configuration.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(circular)
library(stats)
library(reshape2)
library(dplyr)
library(sp)
library(ggplot2)
library(spatstat)
library(lme4)

#===========================================================#
#------Begin function to calculate Determinism--------------#
#===========================================================#

#x is a vector of numbered resource visits/behaviors
#minl is the minimum length of a diagonal to be considered in the 
#numerator of the determinism calculation
filterout <- function(Ldata){
  for (i in 2:length(Ldata)){
    if(Ldata[i] == Ldata[i-1] ){Ldata[i - 1]= NA}
  }
  Ldata=Ldata[!is.na(Ldata)]
  Ldata
}


determinism <- function(x, minl){
  
  x = as.numeric(x)
  #Depending on the dataset it may be desirable to filter out consecutive visits 
  #to the same flower. See function below and delete '#' in the line below to use
  x = filterout(Ldata = x)
  
  #-----set up matrix resembling a recurrence plot, where a 1 indicates a repeat 
  #-----visit and 0 indicates the absence of a repeat.
  if (length(x) <= 3*minl) return(NA)
  if (length(unique(x)) == length(x)) return(0)
  det1 = matrix(cbind(rep(x,length(x))),nrow=length(x))
  tdet = t(det1)
  det = ((det1 - tdet) == 0) * 1
  
  #set the main diagonal equal to zero so it won't be included in the calculation
  
  diag(det) = 0
  
  #Use spatstat package to create a 'countour map' of the matrix,
  #which assigns all sets of contiguous 1's a unique number
  yi <- as.im(det)
  ycOut <- connected(yi, background = 0)
  yc <- ycOut$v
  
  #Depending on the dataset it may be desirable to filter out diagonals perpendicular to #the main diagonal. Code is provided for the 'removeperpdiag' function below.
  #Delete "#" from the line below to filter out perpendicular diagonals
  
  #yc = removeperpdiag(yc,minl)
  
  #Note: this code may take several minutes to run for very long sequences
  
  #---- filter out short repeats: a 'trapline' should include more unique resources
  #---- than the minimum cutoff (minl)
  
  #make an alternative DET matrix that contains the resource IDs
  det2 = matrix(rep(x,nrow(det)),nrow=nrow(det),byrow=TRUE)*det
  #make a dataframe with the number of times each resource appears in a diagonal
  listofseq = data.frame(group = yc[1:length(yc)], seq=det2[1:length(det2)])
  #how many unique resources are in the diagonal
  uniquevisits = rowSums((table(listofseq)>0)*1)
  #only count diagonals with at least 'minl' number of unique resources
  longenough = (uniquevisits >= minl)*table(yc)
  #find the numerator:
  #(remember this still includes both the top and bottom halves of the matrix)
  
  contig = sum(longenough)
  
  denominator= sum(det)
  
  #This also still includes top and bottom halves of the matrix
  
  
  #------------------- total DET score
  #divide the numerator and denominator in half before calculating DET for just
  #the top half of the matrix
  
  return((contig/2)/(denominator/2))
}
```


```{r load data}
setwd("~/Manuscripts/Traplining Vervets/Simulations")
sensitivityResults <- read.csv("AyersSensitivityReplication.csv")
load("sensitivityAnalysisSequences.RData")
```
The data loaded above were generated by running 100 simulations for each combination of parameter levels described below:

abundance (10, 20, 30): Describes the total number of patch locations in the simulation. 
  -Patch locations were determined by sampling from random uniform distributions between -10 and 10 in both the x and y dimensions

sight (10,5,1): The distance at which foragers can detect patches. 
  -If a forager does not already have a target, it will select a target from all patches within its sight distance and move directly toward that target until it arrives. 
  
CRW (0,0.3,0.9): The concentration parameter of the wrapped cauchy distribution from which turning deviations are drawn if a forager is not moving toward a target.
  -At 0, a foragers bearing is independant of its bearing in the previous time-step
  -at 1, a foragers bearing is identical to its bearing in the previous time step

distanceForagers (TRUE, FALSE): When TRUE, foragers are less likely to select visible patches that are farther away. When FALSE, foragers are equally likely to target any visible patch.
  -distance discounting in the TRUE condition is cubic
  
As in Ayers et al 2018, Foragers would not return to the last two patches visited. The data is checked for format consistency below. Some sample plots of simulated enviornments and movements are in the same folder as this document. DET of each simulated sequences of patch visitations is calclulated using minimum length of repeated sequences as 6 (as reported in Ayers et al.)


```{r data check}
#Investigate NAs
sensitivityResults[which(is.na(sensitivityResults$DET)),] #initially a check I put in the determinism function was creating NA's. I removed this line of code and no NAs were produced

#check sequence lengths
summary(sapply(sequences, length)) #should all be 80, the length of sequences analyzed in Ayers et al 2018
```

Data Visualization: Main Effects

```{r pressure, echo=FALSE}
ggSensitivity <- ggplot(sensitivityResults %>% filter(distanceForagers == FALSE))
ggSensitivity + geom_boxplot(aes(x = factor(abundance), y = DET)) + theme_classic() #DETs are very low
ggSensitivity + geom_boxplot(aes(x = factor(sight), y = DET)) + theme_classic()
ggSensitivity + geom_boxplot(aes(x = factor(CRW), y = DET)) + theme_classic()
```

Some important things to note here. First, these values are very low. Ayers et al report using a minL of 6, but this creates a significan floor effect and would seem a poor choice. Later plots in their supplementary materials suggest this is in error, and reported values were actually calculated at miniumum length of 3 or 4.

I also wanted to see why there were outliers in the data, so I looked at plots from simulations with high DET.

```{r outliers}
#Explore Outliers
which(sensitivityResults$DET > 0.4) #look at saved plots
sensitivityResults[which(sensitivityResults$DET > 0.4),] #parameters at which outlier simulations were created
```

These plots suggest high DET values are the result of patch arrangements in which foragers essentially get stuck in a subset of patches, reducing the overall set of possible options. it happens most often at low abundance and middling sight range, when random clusters may all be within sight range of each other, but out of sight of any other patches.

Given how low most DET scores are, I tried recalculating DET at a lower minL

```{r DET3}
#Try DET at different minL
sensitivityResults$DET_minl3 <- sapply(sequences, determinism, minl = 3)
ggSensitivity <- ggplot(sensitivityResults %>% filter(distanceForagers == FALSE))
ggSensitivity + geom_boxplot(aes(x = factor(abundance), y = DET_minl3)) + theme_classic()
ggSensitivity + geom_boxplot(aes(x = factor(sight), y = DET_minl3)) + theme_classic()
ggSensitivity + geom_boxplot(aes(x = factor(CRW), y = DET_minl3)) + theme_classic()
```

These values look much easier to work with, and much closer to the DET's seen in Ayers et al's supp material 1

I used the DETs calculated at both minimum length values to look at the parameters interactions described in Ayers et al supp material 1
```{r DET6 interactions}
#visualize means and interactions
sensitivitySummary <- sensitivityResults %>% filter(distanceForagers == FALSE) %>% group_by(abundance, sight) %>% summarize(mean = mean(DET, na.rm = TRUE), Error = sqrt(var(DET, na.rm = TRUE)/length(DET)))
ggplot(sensitivitySummary, aes(x = abundance, y = mean, color = factor(sight))) + geom_line(aes(group = sight)) + 
  geom_point() + geom_errorbar(aes(ymin = mean - Error, ymax = mean + Error), width = 0.1) + theme_classic()

CRWSummary <- sensitivityResults %>% filter(distanceForagers == FALSE) %>% group_by(abundance, sight, CRW) %>% summarize(mean = mean(DET, na.rm = TRUE), Error = sqrt(var(DET, na.rm = TRUE)/length(DET)))
ggplot(CRWSummary, aes(x = abundance, y = mean, color = factor(CRW))) + geom_line(aes(group = factor(CRW))) + facet_wrap(~sight) +
  geom_point() + geom_errorbar(aes(ymin = mean - Error, ymax = mean + Error), width = 0.5) + theme_classic() + scale_color_brewer(type = "seq", palette = "RdPu")
```

As you can see, the DET values are MUCH lower than those seen in the same figure in the Ayers supplement. With values this low, there is likely to be serious floor effect, where potential effects are missed because everything is just too close to 0. The figure for DET with minL three looks much more like the one in Ayers, and makes for analyzable data.

```{r DET3 interactions}
sensitivitySummaryMinL3 <- sensitivityResults %>% filter(distanceForagers == FALSE) %>% group_by(abundance, sight) %>% summarize(mean = mean(DET_minl3, na.rm = TRUE), Error = sqrt(var(DET_minl3, na.rm = TRUE)/length(DET_minl3)))
ggplot(sensitivitySummaryMinL3, aes(x = abundance, y = mean, color = factor(sight))) + geom_line(aes(group = sight)) + 
  geom_point() + geom_errorbar(aes(ymin = mean - Error, ymax = mean + Error), width = 0.1) + theme_classic()

CRWSummaryMinL3 <- sensitivityResults %>% filter(distanceForagers == FALSE) %>% group_by(abundance, sight, CRW) %>% summarize(mean = mean(DET_minl3, na.rm = TRUE), Error = sqrt(var(DET_minl3, na.rm = TRUE)/length(DET_minl3)))
ggplot(CRWSummaryMinL3, aes(x = abundance, y = mean, color = factor(CRW))) + geom_line(aes(group = factor(CRW))) + facet_wrap(~sight) +
  geom_point() + geom_errorbar(aes(ymin = mean - Error, ymax = mean + Error), width = 0.5) + theme_classic() + scale_color_brewer(type = "seq", palette = "RdPu")
```

These still don't look exactly the same as the Ayers data, but they are much closer. The only noticeable difference is the higer DET scores with a sight level of 1 in my simulations. I think the most likely explanation for this is field size. I was unable to determine exaclty how big the environment was for the Ayers simulations. Because resource abundance is given as an absolute value, but it is really the resource density that is affecting DET with respect to sight range, we would expect the different environment sizes to effectively shift the x axis. It is probably worth reaching out to Ayers to clarify this.

Next, I checked the linear models tested in Ayers to see if the results were the same.
```{r Sensitivity Models}
modelminL6 <- glm(DET ~ abundance * sight * factor(CRW), data = filter(sensitivityResults, distanceForagers == FALSE, !CRW == 0.3))
summary(modelminL6)

modelminL3 <- glm(DET_minl3 ~ abundance * sight * factor(CRW), data = filter(sensitivityResults, distanceForagers == FALSE, !CRW == 0.3))
summary(modelminL3)
```
Unlike Ayers et al., I did not find significant main effects of abundance or sight level. This is somewhat surprsing given the visualization of those data, perhaps the effect was obscured by the non-linear trend (ie DET goes up in the middle level of abundance). Ayers et al also did more simulations than I did, and so would have more power in their tests. I did find the same significant interactions. I would like to know more about how Ayers fit their model; they report using an error distribution I am not familiar and other model-fitting decisions may further shape these differences.

I also checked whether the patch selection methods I implemented had the same effects on DET as those by Ayers et al. Recall, One method selects from patchs within sight with equal probability, while the other discounts each probability relative to the cubed distances to each patch
```{r Patch Choice Sensitivity}
choiceSummary <- sensitivityResults %>% group_by(abundance, sight, distanceForagers) %>% summarize(mean = mean(DET, na.rm = TRUE), Error = sqrt(var(DET, na.rm = TRUE)/length(DET)))
ggplot(choiceSummary, aes(x = abundance, y = mean, color = factor(sight))) + geom_line(aes(group = factor(sight))) + facet_wrap(~distanceForagers) +
  geom_point() + geom_errorbar(aes(ymin = mean - Error, ymax = mean + Error), width = 0.5) + theme_classic()
choiceSummaryMinl3 <- sensitivityResults %>% group_by(abundance, sight, distanceForagers) %>% summarize(mean = mean(DET_minl3, na.rm = TRUE), Error = sqrt(var(DET_minl3, na.rm = TRUE)/length(DET_minl3)))
ggplot(choiceSummaryMinl3, aes(x = abundance, y = mean, color = factor(sight))) + geom_line(aes(group = factor(sight))) + facet_wrap(~distanceForagers) +
  geom_point() + geom_errorbar(aes(ymin = mean - Error, ymax = mean + Error), width = 0.5) + theme_classic()
```

These generally matched (again for minl of 3), so I went on to explore how sight distance and patch selection method affected DET of simulated paths in the Double Trapezoid Array. I also wanted to look at how the avoidance of recently visited platforms shapes DET, hypothesizing that a simple rule of "avoid recently visited patlforms" that extends beyond the last two would increase DET
 
```{r DT Sims}
setwd("~/Manuscripts/Traplining Vervets/Simulations/DT")
setwd("~/Manuscripts/Traplining Vervets/Simulations/DT")
load("DTsimulationSequences.RData")
DTSimulationResults <- read.csv("DTsimulationResults.csv")
ggplot(DTSimulationResults, aes(x = sight, y = DET3, color = factor(AvoidLength))) + geom_point(aes(group = AvoidLength)) + facet_wrap(~distanceForager) + theme_classic()
ggplot(DTSimulationResults, aes(x = sight, y = DET6, color = factor(AvoidLength))) + geom_point(aes(group = AvoidLength)) + facet_wrap(~distanceForager) + theme_classic()
modelDT <- glm(DET3 ~ sight * distanceForager * AvoidLength, data = DTSimulationResults)
summary(modelDT)
``` 

Using minl of 3, we see significant main effects of all three parameters as well as the interaction of sight by selection method and the three way interaction. These effects are further visualized below.

```{r DT Sims 2}
ggplot(DTSimulationResults, aes(x = factor(AvoidLength), y = DET3)) + geom_boxplot() + theme_classic()
ggplot(DTSimulationResults, aes(x = factor(distanceForager), y = DET3)) + geom_boxplot() + theme_classic()
ggplot(DTSimulationResults, aes(x = sight, y = DET3)) + geom_point() + theme_classic() + scale_x_continuous(breaks = seq(5, 25, by = 5))
ggplot(DTSimulationResults, aes(x = sight, y = DET3, color = factor(distanceForager))) + geom_point() + theme_classic()
```

Two interesting things jump out at me here.

First, I noticed the DET actually goes down if the foragers are avoiding more of the recently visited platforms. This was not intuitive to me at first, but I think the effect may be caused because longer "memory" for visited platforms means where you have been is more likely to influence your decision. Thus, the decision an animal makes from a platform if it is the second platform visited will be different than if it is the sixth. If this is the case, we would expect this effect to dissapear at higher DET.

```{r DT AvoidLength DET6}
ggplot(DTSimulationResults, aes(x = factor(AvoidLength), y = DET6)) + geom_boxplot() + theme_classic()
```

Indeed, at DET 6, the effect is opposite!! This is a very interesting interaction, and one that may be worth going into a bit on the paper.

The second interesting result from these simulations is the difference in DET between random selection foragers and distance weighting foragers at high sight ranges. I think this effect is quite intuitive: random foragers with high sight are going to be equally likely to pick from many disant patches, while distance discounting foragers may still see those patches, but rarely select them. This does, however, reflect an interesting property of these simulations that should be of concern to us. By expanding the sight range to include all options, we are removing random movement element that the simulations were designed for. Essentially, we could replicate these results by simply generating sequences from a transition matrix (one in which all transitions are equally likely, and the other in which they are equal to the proportion of cubed distances.) The point of the Ayers simulations was to show that the bees patch sequences are more predictable than expected from random movement; because the patches are too far apart to detect, they must be using memory to do this. Hence, traplining. Under the assumption that a forager CAN see all the options, the random movement properties are obviated, and what we show instead is that primates are more consistent in their choices than expected by random selection (or as I will show in a moment, distance weighted random selection). That is interesting, but I don't think it is traplining. I discuss further in my summary (email).

This last point aside, since our interest is primarily at high sight levels, I ran a final set of 1000 simulations that held all parameters constant (sight = 25, repeat avoid = 2, speed = 4) except the patch selection method (500 simulations each)

```{r DT High Sight Sims}
setwd("~/Manuscripts/Traplining Vervets/Simulations/DT High Sight")
DTSimHighSight <- read.csv("DTSimHighSight.csv")
ggplot(DTSimHighSight, aes(x = distanceForager, y = DET3)) + geom_boxplot() + theme_classic()
ggplot(DTSimHighSight, aes(x = distanceForager, y = DET6)) + geom_boxplot() + theme_classic()
modelDT3 <- glm(DET3 ~ distanceForager, data = DTSimHighSight)
summary(modelDT3)
modelDT6 <- glm(DET6 ~ distanceForager, data = DTSimHighSight)
summary(modelDT6)
```

It is these simulations to which I compare the empirical data, which I recalculated DETs at minl = 3 to double check.

```{r Check Empirical DETs}
setwd("~/Manuscripts/Traplining Vervets")
PrimateDET_Data <- read.csv("DET data.csv") #this is the DET data tab saved as a csv
PrimateDET_Data$Seq <- strsplit(as.character(PrimateDET_Data$Seq), split = ",") #turn vector of factors into list of character vectors
PrimateDET_Data <- PrimateDET_Data[1:183, 1:8] #remove extraneous rows and colums(note stray value in row 73)
DET3_compare <- sapply(PrimateDET_Data$Seq, determinism, minl = 3)
summary(PrimateDET_Data$DET..3. - DET3_compare) # results mostly the same, check few differences
PrimateDET_Data$DET6 <- sapply(PrimateDET_Data$Seq, determinism, minl = 6)
PrimateDETs_cleaned <- PrimateDET_Data[sapply(PrimateDET_Data$Bin.of.10, function(X) X %in% c(1:20)),] #removes incomplete bins. Including partial sets requires some thought - probably simulating sequences with each possible number of trials. Shouldn't be too hard
colnames(PrimateDETs_cleaned) <- c("Array", "Species", "Ind", "Ind.total.trials", "binNum", "DET3", "DET.all.trials", "Seq", "DET6") #clean up and standardize column names
```

There were a few small difference in my results from yours, which may be worth investigating, but overall things look the same. Next I set up a dataframe to compare simulated and empiracal DET values . . .

```{r Empirical v Simulated data set up}
analysis_df <- DTSimHighSight[,-c(1,2)]
names(analysis_df) <- c("Species", "DET3", "DET6")
analysis_df$Array = "DT"
analysis_df$Species[analysis_df$Species] <- "distanceWeightedSim" #turns dForager logical into generating model name
analysis_df$Species[analysis_df$Species == "FALSE"] <- "randomSim" #turns dForager logical into name
analysis_df$Ind <- as.character(1:nrow(analysis_df)) #is this the right way to handle random effect of Individual in simulation data?
analysis_df$Ind.total.trials <- NA
analysis_df$binNum <- NA #may need to add if want to include sims in an interaction model with binNum*Species
analysis_df$DET.all.trials <- NA
analysis_df$Seq <- NA #accidently removed sequences variable! be sure to save for next simulation!
analysis_df <- rbind(analysis_df, PrimateDETs_cleaned)
analysis_df$Species = factor(analysis_df$Species, c("distanceWeightedSim", "randomSim", "Aye-aye", "Dwarf lemur", "Mouse lemur", "Vervet")) # sets order of factor levels for easier comparison to distanceWeightedSim in model output
```

. . . Visualized the resulting data . . .

```{r Empirical vs Simulated Viz}
ggplot(analysis_df, aes(x = Species, y = DET3)) + geom_boxplot() + theme_classic() #primates appear to be higher than simulations!
ggplot(analysis_df, aes(x = Species, y = DET6)) + geom_boxplot() + theme_classic() #Vertvets do show up pretty high here. Worth looking into the data to see if we can figure out why (do they start in the same location more? develop preferred decisions? Choose NN more often? I think you did this and decided on the last one)
```

. . . and built a linear model

```{r Emp v Sim linear model}
#linearDETModel <- lmer(DET3 ~ Species + 1|Ind, data = analysis_df) #doesn't like random effects, this should be figured out
linearDETModel <- glm(DET3 ~ Species, data = analysis_df) #this should maybe just be an ANOVA?
summary(linearDETModel) #Significant effects for all but mouse lemurs
```

This is a very simple model, and I think it will be important to figure out how to add random effects of indivdual to this, which I was not able to figure out (it is tricky to consider what an "individual" is in the simulated data). As is, it is essentially just an ANOVA, which comes with the advantage that it is easy to explain. When looking at DET with minL of six, the floor effect I mentioned earlier is apparent, with many 0s. At DET with minl = 3, however, the data have a nicer, more normal distribution, with significant differences in ALL species from the random choice model and all but the mouse lemurs in the distance discounting model.

So, here are my major takeaways:

1) Simulating movement with high sight is the correct choice because it reflects the reality of our experiments. However, doing so obviates the need for a spatially explicit simulation. We could just as well have built transition matrices to generate our null sequences.
2) Because animals can see all of the platforms/patches, I am of the opinion that this is NOT traplining. Traplining, as it seems to be used throughout the literature, implies spatial memory: the formation of routes from learned responses to visual cues. Our primates are not doing this.
3) Our data DO show that primates choices (except mouse lemurs) are more consistent than expected even given strong distance discounting. This suggests either a very strong nearest neighbor heuristic, or some other consistent decision making bias/preference. You have already gone a bit into what that might be, and this analysis could be a valuable way of approaching that.
4) The ability for foragers to avoid an increasing number of recently visited patches also has an effect on DET, and the effect changes with minL. This IS an aspect of memory at play in the platform experiments, a property of DET not discussed by Ayers, and potentially a really interesting angle to take. 
